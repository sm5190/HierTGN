{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "import json\n",
    "from py2neo import Graph, Node, Relationship\n",
    "import chardet\n",
    "from datetime import datetime\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "from queue import Queue\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Thread-local storage for Neo4j connections\n",
    "thread_local = threading.local()\n",
    "\n",
    "'''\n",
    "Include this in your neo4j DB before run the code:\n",
    "CREATE CONSTRAINT unique_user_id IF NOT EXISTS FOR (u:User) REQUIRE u.user_id IS UNIQUE;\n",
    "CREATE CONSTRAINT unique_tweet_id IF NOT EXISTS FOR (t:Tweet) REQUIRE t.tweet_id IS UNIQUE;\n",
    "'''\n",
    "# Define your connection parameters\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"12345678\"\n",
    "database = \"neo4j\"\n",
    "\n",
    "# Connection pool settings\n",
    "MAX_THREADS = 4  # Adjust based on your system's capabilities\n",
    "MAX_CONNECTIONS = 4  # Match with number of threads\n",
    "\n",
    "# Thread-safe counter for monitoring progress\n",
    "processed_items = Queue()\n",
    "\n",
    "def get_graph_connection():\n",
    "    \"\"\"Get or create a thread-local Neo4j connection.\"\"\"\n",
    "    if not hasattr(thread_local, \"graph\"):\n",
    "        thread_local.graph = Graph(uri, auth=(username, password), name=database)\n",
    "    return thread_local.graph\n",
    "\n",
    "def convert_timestamp(timestamp):\n",
    "    try:\n",
    "        if not timestamp:\n",
    "            print(\"No Stamp Found\")\n",
    "            return None\n",
    "        return datetime.strptime(timestamp, '%a %b %d %H:%M:%S +0000 %Y').isoformat()\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting timestamp {timestamp}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_annotations(annotations_file):\n",
    "    with open(annotations_file, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        # Return empty string if text is None\n",
    "        if text is None:\n",
    "            return \"\"\n",
    "            \n",
    "        # Convert to string if not already\n",
    "        text = str(text)\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "        # Remove mentions and hashtags\n",
    "        text = re.sub(r'@[A-Za-z0-9_]+|#[A-Za-z0-9_]+', '', text)\n",
    "        # Remove special characters and punctuation\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        # Remove extra spaces\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error in text preprocessing: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def load_annotation(annotation_path):\n",
    "    \"\"\"Load the annotation JSON file from the specified path.\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(annotation_path):\n",
    "            with open(annotation_path, \"r\") as annotation_file:\n",
    "                return json.load(annotation_file)\n",
    "        else:\n",
    "            print(f\"Annotation file not found: {annotation_path}\")\n",
    "            return {}\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading annotation file {annotation_path}: {e}\")\n",
    "        return {}\n",
    "'''\n",
    "def convert_annotations(annotation, string=True, is_rumour=True):\n",
    "    \"\"\"Convert annotation dictionary to a label based on its contents.\"\"\"\n",
    "    if not annotation or not isinstance(annotation, dict):\n",
    "        print(\"No annotation File found\")\n",
    "        return \"unknown\" if string else 4\n",
    "    \n",
    "    if not is_rumour:\n",
    "        return \"non-rumour\" if string else 3  # Assign a distinct label for non-rumours\n",
    "\n",
    "    if 'misinformation' in annotation.keys() and 'true' in annotation.keys():\n",
    "        if int(annotation['misinformation']) == 0 and int(annotation['true']) == 0:\n",
    "            return \"unverified\" if string else 2\n",
    "        elif int(annotation['misinformation']) == 0 and int(annotation['true']) == 1:\n",
    "            return \"true\" if string else 1\n",
    "        elif int(annotation['misinformation']) == 1 and int(annotation['true']) == 0:\n",
    "            return \"false\" if string else 0\n",
    "        elif int(annotation['misinformation']) == 1 and int(annotation['true']) == 1:\n",
    "            print(\"Both misinformation and true are set to 1!\")\n",
    "            return None\n",
    "'''    \n",
    "def convert_annotations(annotation, string = True, is_rumour=True):\n",
    "    if 'misinformation' in annotation.keys() and 'true'in annotation.keys():\n",
    "        if int(annotation['misinformation'])==0 and int(annotation['true'])==0:\n",
    "            if string:\n",
    "                label = \"unverified\"\n",
    "            else:\n",
    "                label = 2\n",
    "        elif int(annotation['misinformation'])==0 and int(annotation['true'])==1 :\n",
    "            if string:\n",
    "                label = \"true\"\n",
    "            else:\n",
    "                label = 1\n",
    "        elif int(annotation['misinformation'])==1 and int(annotation['true'])==0 :\n",
    "            if string:\n",
    "                label = \"false\"\n",
    "            else:\n",
    "                label = 0\n",
    "        elif int(annotation['misinformation'])==1 and int(annotation['true'])==1:\n",
    "            print (\"OMG! They both are 1!\")\n",
    "            print(annotation['misinformation'])\n",
    "            print(annotation['true'])\n",
    "            label = None\n",
    "            \n",
    "    elif 'misinformation' in annotation.keys() and 'true' not in annotation.keys():\n",
    "        # all instances have misinfo label but don't have true label\n",
    "        if int(annotation['misinformation'])==0:\n",
    "            if string:\n",
    "                label = \"unverified\"\n",
    "            else:\n",
    "                label = 2\n",
    "        elif int(annotation['misinformation'])==1:\n",
    "            if string:\n",
    "                label = \"false\"\n",
    "            else:\n",
    "                label = 0\n",
    "                \n",
    "    elif 'true' in annotation.keys() and 'misinformation' not in annotation.keys():\n",
    "        print ('Has true not misinformation')\n",
    "        label = None\n",
    "    else:\n",
    "        print('No annotations')\n",
    "        label = None\n",
    "           \n",
    "    return label\n",
    "\n",
    "def create_event_node(event_name):\n",
    "    \"\"\"Create an event node with a timestamp.\"\"\"\n",
    "    graph = get_graph_connection()\n",
    "    event_node = Node(\"Event\", name=event_name)\n",
    "    graph.merge(event_node, \"Event\", \"name\")\n",
    "    print(f\"Created Event node: {event_name}\")\n",
    "    return event_node\n",
    "\n",
    "def create_user_node(user_data):\n",
    "    \"\"\"Create a user node based on tweet user data.\"\"\"\n",
    "    try:\n",
    "        graph = get_graph_connection()\n",
    "        user_node = Node(\n",
    "            \"User\", \n",
    "            user_id=user_data.get(\"id\"), \n",
    "            screen_name=user_data.get(\"screen_name\"), \n",
    "            verified=user_data.get(\"verified\"),\n",
    "            follower_count=user_data.get(\"followers_count\", 0),\n",
    "            description=preprocess_text(user_data.get(\"description\", \"\")),\n",
    "            friends_count=user_data.get(\"friends_count\", 0),\n",
    "            favourites_count=user_data.get(\"favourite_count\", 0),\n",
    "            created_at=convert_timestamp(user_data.get(\"created_at\")),\n",
    "            influencer_score=(\n",
    "                user_data.get(\"followers_count\", 0) * 2 + \n",
    "                user_data.get(\"friends_count\", 0) * 0.5 + \n",
    "                (100 if user_data.get(\"verified\") else 0)\n",
    "            )\n",
    "        )\n",
    "        graph.merge(user_node, \"User\", \"user_id\")\n",
    "        return user_node\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating user node: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_tweet_node(tweet_data, annotation_label):\n",
    "    \"\"\"Create a tweet node based on tweet data.\"\"\"\n",
    "    try:\n",
    "        graph = get_graph_connection()\n",
    "\n",
    "        tweet_text = tweet_data.get(\"text\", \"\")\n",
    "        hashtag_count = len(re.findall(r'#\\w+', tweet_text)) if pd.notnull(tweet_text) else 0\n",
    "        mention_count = len(re.findall(r'@\\w+', tweet_text)) if pd.notnull(tweet_text) else 0\n",
    "        url_count = len(re.findall(r'http[s]?://\\S+', tweet_text)) if pd.notnull(tweet_text) else 0\n",
    "\n",
    "        tweet_node = Node(\n",
    "            \"Tweet\", \n",
    "            tweet_id=tweet_data.get(\"id_str\"),\n",
    "            \n",
    "            hashtag_count=hashtag_count,\n",
    "            mention_count = mention_count,\n",
    "            url_count=url_count,\n",
    "\n",
    "            text=preprocess_text(tweet_data.get(\"text\", \"\")),\n",
    "            user_id=tweet_data.get(\"user\", {}).get(\"id_str\"),\n",
    "            favorite_count=tweet_data.get(\"favorite_count\", 0),\n",
    "            retweet_count=tweet_data.get(\"retweet_count\", 0),\n",
    "            retweeted=tweet_data.get(\"retweeted\", False),  # Default to False if not provided\n",
    "            annotation_label=annotation_label  # Default to \"unknown\" if not present\n",
    "        )\n",
    "     \n",
    "        graph.merge(tweet_node, \"Tweet\", \"tweet_id\")\n",
    "\n",
    "        in_reply_to_status_id = tweet_data.get(\"in_reply_to_status_id_str\")\n",
    "        if in_reply_to_status_id:\n",
    "            replied_to_tweet_node = graph.nodes.match(\"Tweet\", tweet_id=in_reply_to_status_id).first()\n",
    "            if not replied_to_tweet_node:\n",
    "                replied_to_tweet_node = Node(\"Tweet\", tweet_id=in_reply_to_status_id)\n",
    "                graph.merge(replied_to_tweet_node, \"Tweet\", \"tweet_id\")\n",
    "\n",
    "            replied_to_relationship = Relationship(tweet_node, \"REPLIED_TO\", replied_to_tweet_node)\n",
    "            replied_to_relationship[\"timestamp\"] = convert_timestamp(tweet_data.get(\"created_at\"))\n",
    "            graph.merge(replied_to_relationship)\n",
    "\n",
    "        return tweet_node\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating tweet node: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_relationships(user_node, tweet_node, event_node, date):\n",
    "    \"\"\"Create relationships with thread-local graph connection.\"\"\"\n",
    "    if all([user_node, tweet_node, event_node]):\n",
    "        graph = get_graph_connection()\n",
    "        try:\n",
    "            posted_relationship = Relationship(user_node, \"WROTE\", tweet_node)\n",
    "            posted_relationship[\"timestamp\"] = date\n",
    "            graph.merge(posted_relationship)\n",
    "            related_to_relationship = Relationship(tweet_node, \"RELATED_TO\", event_node)\n",
    "            related_to_relationship[\"start_time\"] = date\n",
    "            graph.merge(related_to_relationship)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating relationships: {e}\")\n",
    "\n",
    "def process_tweet_file(file_path, event_node, annotation_label):\n",
    "    \"\"\"Process a single tweet file with thread-local graph connection.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            raw_data = f.read()\n",
    "            encoding = chardet.detect(raw_data)['encoding']\n",
    "\n",
    "        with open(file_path, \"r\", encoding=encoding) as file:\n",
    "            tweet_data = json.load(file)\n",
    "            user_data = tweet_data.get(\"user\")\n",
    "            \n",
    "            if user_data:\n",
    "                user_node = create_user_node(user_data)\n",
    "                tweet_node = create_tweet_node(tweet_data, annotation_label)\n",
    "\n",
    "                print(f\"annotation label of tweet is {tweet_node['annotation_label']}\")\n",
    "\n",
    "                      \n",
    "                create_relationships(user_node, tweet_node, event_node, convert_timestamp(tweet_data[\"created_at\"]))\n",
    "\n",
    "                # Process mentions\n",
    "                graph = get_graph_connection()\n",
    "                for mentioned_user in tweet_data.get(\"entities\", {}).get(\"user_mentions\", []):\n",
    "                    mentioned_user_node = Node(\"User\", \n",
    "                                            user_id=mentioned_user[\"id_str\"],\n",
    "                                            screen_name=mentioned_user[\"screen_name\"])\n",
    "                    graph.merge(mentioned_user_node, \"User\", \"user_id\")\n",
    "                    mention_relationship = Relationship(tweet_node, \"MENTIONS\", mentioned_user_node)\n",
    "                    mention_relationship[\"timestamp\"] = convert_timestamp(tweet_data[\"created_at\"])\n",
    "                    graph.merge(mention_relationship)\n",
    "\n",
    "                processed_items.put(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing tweet file {file_path}: {e}\")\n",
    "\n",
    "def process_tweet_folders_threaded(tweet_folder_path, event_name, tweet_id, category, event_node):\n",
    "    \"\"\"Process tweet folders using thread pool.\"\"\"\n",
    "    annotation_folder = os.path.join(\n",
    "        \"all-rnr-annotated-threads\",\n",
    "        f\"{event_name}-all-rnr-threads\", category, tweet_id\n",
    "    )\n",
    "    annotation_path = os.path.join(annotation_folder, \"annotation.json\")\n",
    "    \n",
    "    annotation_data = load_annotation(annotation_path)\n",
    "    print(f\"Loaded annotation data: {annotation_data}\")\n",
    "    is_rumor = category == \"rumours\"\n",
    "    annotation_label = convert_annotations(annotation_data, is_rumour= is_rumor)\n",
    "    print(f\"Annotation label is : {annotation_label}\")\n",
    "    \n",
    "    #if annotation_label in [\"unknown\", \"invalid\", \"conflicting\"]:\n",
    "    #     print(f\"Note: Using {annotation_label} label for tweet {tweet_id} in {event_name}\")\n",
    "\n",
    "\n",
    "    tasks = []\n",
    "    with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "        for tweet_type in ['reactions', 'source-tweets']:\n",
    "            tweet_type_folder_path = os.path.join(tweet_folder_path, tweet_type)\n",
    "            if os.path.exists(tweet_type_folder_path):\n",
    "                for filename in os.listdir(tweet_type_folder_path):\n",
    "                    if filename.endswith(\".json\") and not filename.startswith(\"_\"):\n",
    "                        file_path = os.path.join(tweet_type_folder_path, filename)\n",
    "                        future = executor.submit(\n",
    "                            process_tweet_file, \n",
    "                            file_path, \n",
    "                            event_node, \n",
    "                            annotation_label\n",
    "                        )\n",
    "                        tasks.append(future)\n",
    "\n",
    "        # Wait for all tasks to complete\n",
    "        for future in as_completed(tasks):\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"Error in thread: {e}\")\n",
    "\n",
    "def process_subfolders_threaded(event_path, event_name, event_node):\n",
    "    \"\"\"Process subfolders using thread pool.\"\"\"\n",
    "    with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "        tasks = []\n",
    "        for subfolder in ['rumours', 'non-rumours']:\n",
    "            subfolder_path = os.path.join(event_path, subfolder)\n",
    "            if os.path.exists(subfolder_path):\n",
    "                for tweet_id in os.listdir(subfolder_path):\n",
    "                    tweet_folder_path = os.path.join(subfolder_path, tweet_id)\n",
    "                    if os.path.isdir(tweet_folder_path):\n",
    "                        future = executor.submit(\n",
    "                            process_tweet_folders_threaded,\n",
    "                            tweet_folder_path,\n",
    "                            event_name,\n",
    "                            tweet_id,\n",
    "                            subfolder,\n",
    "                            event_node\n",
    "                        )\n",
    "                        tasks.append(future)\n",
    "\n",
    "        # Wait for all tasks to complete\n",
    "        for future in as_completed(tasks):\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"Error in thread: {e}\")\n",
    "\n",
    "def process_event_folders(base_directory):\n",
    "    \"\"\"Process event folders with progress monitoring.\"\"\"\n",
    "    start_time = time.time()\n",
    "    processed_count = 0\n",
    "\n",
    "    for event_folder in os.listdir(base_directory):\n",
    "        event_path = os.path.join(base_directory, event_folder)\n",
    "        \n",
    "        if os.path.isdir(event_path):\n",
    "            event_name = event_folder.replace('-all-rnr-threads', '')\n",
    "            timestamp = datetime.now().isoformat()\n",
    "            event_node = create_event_node(event_name)\n",
    "            \n",
    "            process_subfolders_threaded(event_path, event_name, event_node)\n",
    "            \n",
    "            # Process items from the queue\n",
    "            while not processed_items.empty():\n",
    "                processed_items.get()\n",
    "                processed_count += 1\n",
    "                \n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Processed {processed_count} items in {elapsed_time:.2f} seconds\")\n",
    "            print(f\"Average processing rate: {processed_count/elapsed_time:.2f} items/second\")\n",
    "\n",
    "def print_statistics():\n",
    "    \"\"\"Print database statistics using thread-local connection.\"\"\"\n",
    "    graph = get_graph_connection()\n",
    "    \n",
    "    # Query total nodes\n",
    "    result = graph.run(\"MATCH (n) RETURN COUNT(n) AS total_nodes\").data()\n",
    "    total_nodes = result[0]['total_nodes'] if result else 0\n",
    "    print(f\"Total number of nodes: {total_nodes}\")\n",
    "\n",
    "    # Query Event nodes\n",
    "    result = graph.run(\"MATCH (e:Event) RETURN COUNT(e) AS total_events\").data()\n",
    "    total_events = result[0]['total_events'] if result else 0\n",
    "    print(f\"Total number of events: {total_events}\")\n",
    "\n",
    "    # Query User nodes\n",
    "    result = graph.run(\"MATCH (u:User) RETURN COUNT(u) AS total_users\").data()\n",
    "    total_users = result[0]['total_users'] if result else 0\n",
    "    print(f\"Total number of users: {total_users}\")\n",
    "\n",
    "    # Query Tweet nodes\n",
    "    result = graph.run(\"MATCH (t:Tweet) RETURN COUNT(t) AS total_tweets\").data()\n",
    "    total_tweets = result[0]['total_tweets'] if result else 0\n",
    "    print(f\"Total number of tweets: {total_tweets}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_directory = \"all-rnr-annotated-threads\"\n",
    "    \n",
    "    try:\n",
    "        process_event_folders(base_directory)\n",
    "        print(\"\\nProcessing complete. Generating statistics...\")\n",
    "        print_statistics()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during processing: {e}\")\n",
    "    finally:\n",
    "        print(\"Script execution completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
